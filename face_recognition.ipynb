{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# constant path for images \n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tensorflow as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Getting all image from folder</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_names=[]\n",
    "person_names=set()\n",
    "for file_name in glob.glob(os.path.join(path,'Images','[a-zA-Z0-9 .]*.jpg')):\n",
    "    image_path_names.append(file_name)\n",
    "    person_names.add(image_path_names[-1].split('\\\\')[-1].split('_')[0]+image_path_names[-1].split('\\\\')[-1].split('_')[1])\n",
    " \n",
    "# total number of images \n",
    "len(image_path_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AlvaroUribe',\n",
       " 'BillClinton',\n",
       " 'GeorgeW',\n",
       " 'JenniferLopez',\n",
       " 'JoeLieberman',\n",
       " 'JunichiroKoizumi',\n",
       " 'MichaelBloomberg',\n",
       " 'NaomiWatts',\n",
       " 'RudolphGiuliani'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting CNN face detectetor from dlib</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading cnn face detector model \n",
    "dnnFaceDetector=dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a path for crop image \n",
    "if not os.path.exists(os.path.join(path,'Images_crop')):\n",
    "    os.mkdir(os.path.join(path,'Images_crop'))\n",
    "    \n",
    "# For each person create a separate folder\n",
    "for person in person_names:\n",
    "    if not os.path.exists(os.path.join(path,'Images_crop',person)):\n",
    "        os.mkdir(os.path.join(path,'Images_crop',person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0017.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0018.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0019.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0020.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0035.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\AlvaroUribe\\Alvaro_Uribe_0035.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\BillClinton\\Bill_Clinton_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\BillClinton\\Bill_Clinton_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\BillClinton\\Bill_Clinton_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\BillClinton\\Bill_Clinton_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\BillClinton\\Bill_Clinton_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\BillClinton\\Bill_Clinton_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\BillClinton\\Bill_Clinton_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\BillClinton\\Bill_Clinton_0008.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0008.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0010.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\GeorgeW\\George_W_Bush_0011.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0008.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0010.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JenniferLopez\\Jennifer_Lopez_0011.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0008.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0010.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0011.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JoeLieberman\\Joe_Lieberman_0013.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0008.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0010.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0011.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0008.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0010.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0011.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0008.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0010.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\NaomiWatts\\Naomi_Watts_0011.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0001.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0002.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0003.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0004.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0005.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0006.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0007.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0008.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0010.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0011.jpg\n"
     ]
    }
   ],
   "source": [
    "# Detect face, crop detected face and save them in corresponding person folder\n",
    "for file_name in image_path_names:\n",
    "  img=cv2.imread(file_name)\n",
    "  gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  rects=dnnFaceDetector(gray,1)\n",
    "  left,top,right,bottom=0,0,0,0\n",
    "  for (i,rect) in enumerate(rects):\n",
    "    left=abs(rect.rect.left()) #x1\n",
    "    top=abs(rect.rect.top()) #y1\n",
    "    right=abs(rect.rect.right()) #x2\n",
    "    bottom=abs(rect.rect.bottom()) #y2\n",
    "    width=abs(right-left)\n",
    "    height=abs(bottom-top)\n",
    "    img_crop=img[top:top+height,left:left+width]\n",
    "    img_path=os.path.join(path, 'Images_crop', file_name.split('\\\\')[-1].split('_')[0]+file_name.split('\\\\')[-1].split('_')[1], file_name.split('\\\\')[-1])\n",
    "    print(img_path)\n",
    "    cv2.imwrite(img_path,img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Alvaro_Uribe_0021.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Alvaro_Uribe_0022.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Alvaro_Uribe_0033.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Alvaro_Uribe_0034.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Bill_Clinton_0009.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Bill_Clinton_0010.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Bill_Clinton_0011.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Bill_Clinton_0012.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\George_W_Bush_0012.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\George_W_Bush_0013.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\George_W_Bush_0014.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\George_W_Bush_0015.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Jennifer_Lopez_0012.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Jennifer_Lopez_0013.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Jennifer_Lopez_0014.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Jennifer_Lopez_0015.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Junichiro_Koizumi_0012.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Junichiro_Koizumi_0013.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Junichiro_Koizumi_0014.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Junichiro_Koizumi_0015.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Michael_Bloomberg_0012.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Michael_Bloomberg_0013.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Michael_Bloomberg_0014.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Michael_Bloomberg_0015.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Naomi_Watts_0012.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Naomi_Watts_0013.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Naomi_Watts_0014.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Naomi_Watts_0015.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Rudolph_Giuliani_0012.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Rudolph_Giuliani_0013.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Rudolph_Giuliani_0014.jpg', 'c:\\\\Users\\\\adijr\\\\OneDrive\\\\Desktop\\\\Computer Vision\\\\CNN_Project\\\\Images_test\\\\Rudolph_Giuliani_0015.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Get Image names for testing\n",
    "# img_path=os.path.join(path, 'Images_crop', file_name.split('/')[-1].split('_')[0]+file_name.split('/')[-1].split('_')[1], file_name.split('/')[-1])\n",
    "test_image_path_names=[]\n",
    "for file_name in glob.glob(os.path.join(path,'Images_test','[a-zA-Z0-9 .]*.jpg')):\n",
    "  test_image_path_names.append(file_name)\n",
    "print(test_image_path_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_image_path_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(path,'Test_Images_crop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Separate folder for each person in \"Test_Images_crop\" folder\n",
    "for person in person_names:\n",
    "  os.mkdir(os.path.join(path,'Test_Images_crop',person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\AlvaroUribe\\Alvaro_Uribe_0021.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\AlvaroUribe\\Alvaro_Uribe_0022.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\AlvaroUribe\\Alvaro_Uribe_0033.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\AlvaroUribe\\Alvaro_Uribe_0033.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\AlvaroUribe\\Alvaro_Uribe_0034.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\BillClinton\\Bill_Clinton_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\BillClinton\\Bill_Clinton_0009.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\BillClinton\\Bill_Clinton_0010.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\BillClinton\\Bill_Clinton_0011.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\BillClinton\\Bill_Clinton_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\GeorgeW\\George_W_Bush_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\GeorgeW\\George_W_Bush_0013.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\GeorgeW\\George_W_Bush_0014.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\GeorgeW\\George_W_Bush_0015.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\JenniferLopez\\Jennifer_Lopez_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\JenniferLopez\\Jennifer_Lopez_0013.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\JenniferLopez\\Jennifer_Lopez_0014.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\JenniferLopez\\Jennifer_Lopez_0015.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0013.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0014.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\JunichiroKoizumi\\Junichiro_Koizumi_0015.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0013.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0014.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0015.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\MichaelBloomberg\\Michael_Bloomberg_0015.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\NaomiWatts\\Naomi_Watts_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\NaomiWatts\\Naomi_Watts_0013.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\NaomiWatts\\Naomi_Watts_0014.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\NaomiWatts\\Naomi_Watts_0015.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0012.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0013.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0013.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0014.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0015.jpg\n",
      "c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\\Test_Images_crop\\RudolphGiuliani\\Rudolph_Giuliani_0015.jpg\n"
     ]
    }
   ],
   "source": [
    "# Detect face,crop face and save in corresponding folder\n",
    "for file_name in test_image_path_names:\n",
    "  img=cv2.imread(file_name)\n",
    "  gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  rects=dnnFaceDetector(gray,1)\n",
    "  left,top,right,bottom=0,0,0,0\n",
    "  for (i,rect) in enumerate(rects):\n",
    "    left=abs(rect.rect.left()) #x1\n",
    "    top=abs(rect.rect.top()) #y1\n",
    "    right=abs(rect.rect.right()) #x2\n",
    "    bottom=abs(rect.rect.bottom()) #y2\n",
    "    width=abs(right-left)\n",
    "    height=abs(bottom-top)\n",
    "    img_crop=img[top:top+height,left:left+width]\n",
    "    img_path=os.path.join(path, 'Test_Images_crop', file_name.split('\\\\')[-1].split('_')[0]+file_name.split('\\\\')[-1].split('_')[1], file_name.split('\\\\')[-1])\n",
    "    print(img_path)\n",
    "    cv2.imwrite(img_path,img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 1E70-A109\n",
      "\n",
      " Directory of c:\\Users\\adijr\\OneDrive\\Desktop\\Computer Vision\\CNN_Project\n",
      "\n",
      "23-11-2022  19:33    <DIR>          .\n",
      "23-11-2022  19:33    <DIR>          ..\n",
      "12-04-2022  04:58    <DIR>          .ipynb_checkpoints\n",
      "14-04-2022  23:16    <DIR>          All_Images\n",
      "23-11-2022  19:38            52,019 face_recognition.ipynb\n",
      "14-04-2022  23:43    <DIR>          Images\n",
      "12-04-2022  09:00    <DIR>          Images_crop\n",
      "14-04-2022  23:43    <DIR>          Images_test\n",
      "12-04-2022  08:50           729,940 mmod_human_face_detector.dat\n",
      "23-11-2022  19:33    <DIR>          Test_Images_crop\n",
      "15-04-2022  02:06       580,085,408 vgg_face_weights.h5\n",
      "               3 File(s)    580,867,367 bytes\n",
      "               8 Dir(s)  10,171,838,464 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import ZeroPadding2D,Convolution2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense,Dropout,Softmax,Flatten,Activation,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define VGG_FACE_MODEL architecture\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG Face model weights\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d (ZeroPadding  (None, 226, 226, 3)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPaddi  (None, 226, 226, 64)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " zero_padding2d_2 (ZeroPaddi  (None, 114, 114, 64)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " zero_padding2d_3 (ZeroPaddi  (None, 114, 114, 128)    0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_4 (ZeroPaddi  (None, 58, 58, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " zero_padding2d_5 (ZeroPaddi  (None, 58, 58, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " zero_padding2d_6 (ZeroPaddi  (None, 58, 58, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_7 (ZeroPaddi  (None, 30, 30, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " zero_padding2d_8 (ZeroPaddi  (None, 30, 30, 512)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_9 (ZeroPaddi  (None, 30, 30, 512)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_10 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_11 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_12 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 1, 4096)        102764544 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 4096)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 1, 1, 4096)        16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 1, 4096)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 1, 1, 2622)        10742334  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2622)              0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 2622)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Last Softmax layer and get model upto last flatten layer with outputs 2622 units\n",
    "vgg_face=Model(inputs=model.layers[0].input,outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Training Data\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "person_folders=os.listdir(os.path.join(path,'Images_crop'))\n",
    "person_rep=dict()\n",
    "for i,person in enumerate(person_folders):\n",
    "  person_rep[i]=person\n",
    "  image_names=os.listdir(os.path.join('Images_crop', person))\n",
    "  for image_name in image_names:\n",
    "    img=load_img(os.path.join(path,'Images_crop',person,image_name),target_size=(224,224))\n",
    "    img=img_to_array(img)\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    img=preprocess_input(img)\n",
    "    img_encode=vgg_face(img)\n",
    "    x_train.append(np.squeeze(K.eval(img_encode)).tolist())\n",
    "    y_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'AlvaroUribe',\n",
       " 1: 'BillClinton',\n",
       " 2: 'GeorgeW',\n",
       " 3: 'JenniferLopez',\n",
       " 4: 'JoeLieberman',\n",
       " 5: 'JunichiroKoizumi',\n",
       " 6: 'MichaelBloomberg',\n",
       " 7: 'NaomiWatts',\n",
       " 8: 'RudolphGiuliani'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Test Data\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "person_folders=os.listdir(os.path.join(path,'Test_Images_crop'))\n",
    "for i,person in enumerate(person_folders):\n",
    "  image_names=os.listdir(os.path.join('Test_Images_crop',person))\n",
    "  for image_name in image_names:\n",
    "    img=load_img(os.path.join(path,'Test_Images_crop',person,image_name),target_size=(224,224))\n",
    "    img=img_to_array(img)\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    img=preprocess_input(img)\n",
    "    img_encode=vgg_face(img)\n",
    "    x_test.append(np.squeeze(K.eval(img_encode)).tolist())\n",
    "    y_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test and train data for later use\n",
    "np.save('train_data',x_train)\n",
    "np.save('train_labels',y_train)\n",
    "np.save('test_data',x_test)\n",
    "np.save('test_labels',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved data\n",
    "x_train=np.load('train_data.npy')\n",
    "y_train=np.load('train_labels.npy')\n",
    "x_test=np.load('test_data.npy')\n",
    "y_test=np.load('test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax regressor to classify images based on encoding \n",
    "classifier_model=Sequential()\n",
    "classifier_model.add(Dense(units=100,input_dim=x_train.shape[1],kernel_initializer='glorot_uniform'))\n",
    "classifier_model.add(BatchNormalization())\n",
    "classifier_model.add(Activation('tanh'))\n",
    "classifier_model.add(Dropout(0.3))\n",
    "classifier_model.add(Dense(units=10,kernel_initializer='glorot_uniform'))\n",
    "classifier_model.add(BatchNormalization())\n",
    "classifier_model.add(Activation('tanh'))\n",
    "classifier_model.add(Dropout(0.2))\n",
    "classifier_model.add(Dense(units=6,kernel_initializer='he_uniform'))\n",
    "classifier_model.add(Activation('softmax'))\n",
    "classifier_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='nadam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 978, in launch_instance\n      app.start()\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\adijr\\AppData\\Local\\Temp\\ipykernel_8704\\3801494810.py\", line 1, in <module>\n      classifier_model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1862, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5202, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 8 which is outside the valid range of [0, 6).  Label values: 2 6 1 3 2 5 2 8 2 2 7 7 2 2 2 2 2 3 5 5 2 3 2 2 2 7 2 2 2 2 2 2\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_92925]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m classifier_model\u001b[39m.\u001b[39;49mfit(x_train,y_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(x_test,y_test))\n",
      "File \u001b[1;32mc:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\adijr\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 978, in launch_instance\n      app.start()\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\adijr\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\adijr\\AppData\\Local\\Temp\\ipykernel_8704\\3801494810.py\", line 1, in <module>\n      classifier_model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1862, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\adijr\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5202, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 8 which is outside the valid range of [0, 6).  Label values: 2 6 1 3 2 5 2 8 2 2 7 7 2 2 2 2 2 3 5 5 2 3 2 2 2 7 2 2 2 2 2 2\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_92925]"
     ]
    }
   ],
   "source": [
    "classifier_model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder which contains images to be tested and predicted\n",
    "test_images_path=os.path.join(path,'Test_Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnFaceDetector=dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img):\n",
    "  plt.figure(figsize=(8,4))\n",
    "  plt.imshow(img[:,:,::-1])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label names for class numbers\n",
    "person_rep={\n",
    "    0:'AlvaroUribe',\n",
    "    1:'BillClinton',\n",
    "    2:'GeorgeW',\n",
    "    3:'JenniferLopez',\n",
    "    4:'JoeLieberman',\n",
    "    5:'JunichiroKoizumi',\n",
    "    6:'MichaelBloomberg',\n",
    "    7:'NaomiWatts',\n",
    "    8:'RudolphGiuliani'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(path+'Predictions'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in os.listdir('Images_test/'):\n",
    "  if img_name=='crop_img.jpg':\n",
    "    continue\n",
    "  # Load Image\n",
    "  img=cv2.imread(os.path.join(path,'Images_test',img_name))\n",
    "  gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  # Detect Faces\n",
    "  rects=dnnFaceDetector(gray,1)\n",
    "  left,top,right,bottom=0,0,0,0\n",
    "  for (i,rect) in enumerate(rects):\n",
    "    # Extract Each Face\n",
    "    left=rect.rect.left() #x1\n",
    "    top=rect.rect.top() #y1\n",
    "    right=rect.rect.right() #x2\n",
    "    bottom=rect.rect.bottom() #y2\n",
    "    width=right-left\n",
    "    height=bottom-top\n",
    "    img_crop=img[top:top+height,left:left+width]\n",
    "    cv2.imwrite(os.path.join(path+'/Images_test/crop_img.jpg',img_crop))\n",
    "    \n",
    "    # Get Embeddings\n",
    "    crop_img=load_img(path+'/Images_test/crop_img.jpg',target_size=(224,224))\n",
    "    crop_img=img_to_array(crop_img)\n",
    "    crop_img=np.expand_dims(crop_img,axis=0)\n",
    "    crop_img=preprocess_input(crop_img)\n",
    "    img_encode=vgg_face(crop_img)\n",
    "\n",
    "    # Make Predictions\n",
    "    embed=K.eval(img_encode)\n",
    "    person=classifier_model.predict(embed)\n",
    "    name=person_rep[np.argmax(person)]\n",
    "    os.remove(path+'/Images_test/crop_img.jpg')\n",
    "    cv2.rectangle(img,(left,top),(right,bottom),(0,255,0), 2)\n",
    "    img=cv2.putText(img,name,(left,top-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "    img=cv2.putText(img,str(np.max(person)),(right,bottom+10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "  # Save images with bounding box,name and accuracy \n",
    "  cv2.imwrite(os.path.join(path,'Predictions',img_name),img)\n",
    "  plot(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1440f021e17182a9c0159ecb23cc3edc6c9625118eb0d3610570c15d1ea9907b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
